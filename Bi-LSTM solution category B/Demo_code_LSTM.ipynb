{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","# Demo Code for NLU Coursework Bi-LSTM Model Inference\n","\n","## Before we begin:\n","- Upload:\n","  - pre-trained model: 'Bi-lstm_model.h5'\n","  - Tokenizer: 'tokenizer.joblib'\n","  - File name of the test data\n","\n"," , Directly to this Colab session before proceeding.\n","- These files are the result of training the Bi-LSTM model on the NLI task, and the trained Tokenizer used for pre-processing.\n","\n"],"metadata":{"id":"RflHortyFoiq"}},{"cell_type":"code","source":["# Installation of required packages (if not already available in the Google Colab environment)\n","# Run the following lines if you encounter import errors, or if instructed by the notebook\n","!pip install joblib\n","!pip install pandas  # Usually, pandas is pre-installed in Google Colab\n","!pip install keras\n","!pip install tensorflow\n"],"metadata":{"id":"8O-MBCbaGVqr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Import necessary libraries\n"],"metadata":{"id":"4QVClx38GiOi"}},{"cell_type":"code","source":["import pandas as pd\n","import joblib\n","import os\n","import re\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"y77EUZFjGlbJ","executionInfo":{"status":"ok","timestamp":1714491224328,"user_tz":-60,"elapsed":5656,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["2. Load the pre-trained model, vectorizer, and test dataset for prediction"],"metadata":{"id":"rDjhj1mlGnY7"}},{"cell_type":"code","source":["# Load the pre-trained model and tokenizer\n","try:\n","    lstm_model = load_model('Bi-lstm_model.h5')\n","    tokenizer = joblib.load('tokenizer.joblib')\n","except FileNotFoundError as e:\n","    print(e)\n","    print(\"Please make sure the model and tokenizer files are uploaded to this session.\")\n","    raise  # Exit if files not found.\n"],"metadata":{"id":"Dhip3hHKGqFe","executionInfo":{"status":"ok","timestamp":1714491229419,"user_tz":-60,"elapsed":1274,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load new input data for prediction\n","try:\n","    new_data = pd.read_csv('demo_input.csv') # This is just a placeholder replace with actual file name of the test data\n","except FileNotFoundError:\n","    print(\"Data file not found. Please upload the test dataset to this session.\")\n","    raise"],"metadata":{"id":"FhqDidqGHAMp","executionInfo":{"status":"ok","timestamp":1714491233080,"user_tz":-60,"elapsed":226,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["3. Pre-process test dataset"],"metadata":{"id":"_k3iLQe8HFAz"}},{"cell_type":"code","source":["# Function to preprocess text data\n","def preprocess_text(text):\n","    # Use a lambda function to replace non-alphanumeric characters and convert to lowercase\n","    text = text.apply(lambda t: re.sub('[^\\w\\s]', '', t).lower())\n","    # Tokenize and pad sequences\n","    sequences = tokenizer.texts_to_sequences(text)\n","    padded_sequences = pad_sequences(sequences, maxlen=100)  # Ensure the same max length as during training\n","    return padded_sequences"],"metadata":{"id":"fqg0P9D1HFlK","executionInfo":{"status":"ok","timestamp":1714491235874,"user_tz":-60,"elapsed":205,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["new_data.fillna('', inplace=True)\n","new_data['text'] = new_data['premise'].str.cat(new_data['hypothesis'], sep=' ')\n","X_new = preprocess_text(new_data['text'])"],"metadata":{"id":"TUVd2kAIHYRz","executionInfo":{"status":"ok","timestamp":1714491237606,"user_tz":-60,"elapsed":243,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["4. Make predictions using the loaded model\n"],"metadata":{"id":"ODLbzdCsHb93"}},{"cell_type":"code","source":["predictions = lstm_model.predict(X_new)\n","predictions = (predictions > 0.5).astype(int)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8Ry1iXwHjBn","outputId":"e8015f43-bd70-4b14-cfb8-ca191a940d55","executionInfo":{"status":"ok","timestamp":1714491240194,"user_tz":-60,"elapsed":1188,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 884ms/step\n"]}]},{"cell_type":"markdown","source":["5. Save the predictions to a CSV file in the specified format\n","\n"],"metadata":{"id":"YjiJJBlGHoSf"}},{"cell_type":"code","source":["predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n","predictions_df.to_csv('Group_3_B.csv', header=True, index=False)\n","print(\"Predictions have been saved successfully to 'Group_3_B.csv'\") # Save directly in the session, click on the left-hand side file icon in Google Colab to see the file and downlaod, select refresh by right clicking the files field if file did not appear immedietly\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJ5N4QWaHt3o","outputId":"39c5523a-8d76-4982-815a-dbef3f0b1de5","executionInfo":{"status":"ok","timestamp":1714491243567,"user_tz":-60,"elapsed":220,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions have been saved successfully to 'Group_3_B.csv'\n"]}]},{"cell_type":"code","source":["# Output Verification\n","print(f\"Checking if the output file exists: {'Found' if os.path.isfile('Group_3_B.csv') else 'Not Found'}\")\n","if os.path.isfile('Group_3_B.csv'):\n","    print(\"\\nFirst 5 lines of the prediction file:\")\n","    with open('Group_3_B.csv', 'r') as file:\n","        for _ in range(5):\n","            print(file.readline().strip())\n","else:\n","    print(\"Output file not found. Please check the file path and write permissions.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XtmhGOpHw3M","outputId":"31f84a2f-29f7-4d0c-8f01-31821f67983a","executionInfo":{"status":"ok","timestamp":1714491245836,"user_tz":-60,"elapsed":309,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Checking if the output file exists: Found\n","\n","First 5 lines of the prediction file:\n","prediction\n","1\n","1\n","1\n","1\n"]}]}]}