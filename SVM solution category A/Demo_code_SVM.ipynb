{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3cyf5AGVnHDRoge2OWLu6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","# Demo Code for NLU Coursework SVM Model Inference\n","\n","## Before we begin:\n","- Upload:\n","  - pre-trained model: 'svm_model.joblib'\n","  - Vectorizer:'tfidf_vectorizer.joblib'\n","  - File name of the test data\n","\n"," , Directly to this Colab session before proceeding.\n","- These files are the result of training the SVM model on the NLI task, and the trained vectorizer used for pre-processing.\n","\n"],"metadata":{"id":"JN3sA3tLoGCN"}},{"cell_type":"code","source":["# Installation of required packages (if not already available in the Google Colab environment)\n","# Run the following lines if you encounter import errors, or if instructed by the notebook\n","\n","!pip install joblib  # Used for saving and loading models; included by default in Google Colab, install if missing\n","!pip install pandas  # Used for data manipulation usually pre-installed in Google Colab, install if missing\n","\n"],"metadata":{"id":"L_4Zy1Y2TIE8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Import necessary libraries\n"],"metadata":{"id":"4QervC6RfRiu"}},{"cell_type":"code","source":["import pandas as pd\n","import joblib\n","import os\n","import re"],"metadata":{"id":"N8znMyXnnx2b","executionInfo":{"status":"ok","timestamp":1714491129040,"user_tz":-60,"elapsed":851,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["2. Load the pre-trained model, vectorizer, and test dataset for prediction"],"metadata":{"id":"10yq1PZUfpz8"}},{"cell_type":"code","source":["# Load the pre-trained model and vectorizer, error handling\n","try:\n","    svm_model = joblib.load('svm_model.joblib')\n","    tfidf_vectorizer = joblib.load('tfidf_vectorizer.joblib')\n","except FileNotFoundError as e:\n","    print(e)\n","    print(\"Please make sure the model and vectorizer files are uploaded to this session.\")\n","    raise  # Exit if files not found"],"metadata":{"id":"mRs-BIzPpIpK","executionInfo":{"status":"ok","timestamp":1714491143180,"user_tz":-60,"elapsed":1602,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load new input data for prediction\n","try:\n","    new_data = pd.read_csv('demo_input.csv') # This is just a placeholder replace with actual file name of the test data\n","except FileNotFoundError:\n","    print(\"Data file not found. Please upload the test dataset to this session.\")\n","    raise  # Exit if file not found"],"metadata":{"id":"ayJ4EHnWpN2j","executionInfo":{"status":"ok","timestamp":1714491146016,"user_tz":-60,"elapsed":268,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["3. Pre-process test dataset"],"metadata":{"id":"0OF5ULlhgjdv"}},{"cell_type":"code","source":["# Function to preprocess text data\n","def preprocess_text(text):\n","    # Use a lambda function to replace non-alphanumeric characters and convert to lowercase\n","    return text.apply(lambda t: re.sub('[^\\w\\s]', '', t).lower())\n","# Preprocess the new data\n","new_data.fillna('', inplace=True)\n","new_data['text'] = new_data['premise'].str.cat(new_data['hypothesis'], sep=' ')\n","new_data['text'] = preprocess_text(new_data['text'])\n"],"metadata":{"id":"yuTjoV0kSLx7","executionInfo":{"status":"ok","timestamp":1714491149716,"user_tz":-60,"elapsed":213,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Transform the new data using the loaded vectorizer\n","X_new = tfidf_vectorizer.transform(new_data['text'])"],"metadata":{"id":"XK8-OXhjpSfP","executionInfo":{"status":"ok","timestamp":1714491152837,"user_tz":-60,"elapsed":247,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["4. Generate predictions for the test data using the loaded model"],"metadata":{"id":"CF519MfNhFdI"}},{"cell_type":"code","source":["# Make predictions using the loaded model\n","predictions = svm_model.predict(X_new)"],"metadata":{"id":"o2q1vPnNSTUG","executionInfo":{"status":"ok","timestamp":1714491156242,"user_tz":-60,"elapsed":263,"user":{"displayName":"khawla","userId":"13982007881466537768"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Save the predictions to a CSV file in the specified format\n","predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n","predictions_df.to_csv('Group_3_A.csv', header=True, index=False)\n","print(\"Predictions have been saved successfully to 'Group_3_A.csv'\") # Save directly in the session, click on the left-hand side file icon in Google Colab to see the file and downlaod, select refresh by right clicking the files field if file did not appear immedietly\n","\n","# Output Verification\n","print(f\"Checking if the output file exists: {'Found' if os.path.isfile('Group_3_A.csv') else 'Not Found'}\")\n","if os.path.isfile('Group_3_A.csv'):\n","    print(\"\\nFirst 5 lines of the prediction file:\")\n","    with open('Group_3_A.csv', 'r') as file:\n","        for _ in range(5):\n","            print(file.readline().strip())\n","else:\n","    print(\"Output file not found. Please check the file path and write permissions.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fh9wvr7TmX6a","executionInfo":{"status":"ok","timestamp":1714491164371,"user_tz":-60,"elapsed":284,"user":{"displayName":"khawla","userId":"13982007881466537768"}},"outputId":"26a11413-5acb-438b-fb91-bd515bb56924"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions have been saved successfully to 'Group_3_A.csv'\n","Checking if the output file exists: Found\n","\n","First 5 lines of the prediction file:\n","prediction\n","1\n","0\n","0\n","1\n"]}]}]}